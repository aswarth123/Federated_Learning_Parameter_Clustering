{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedLearning(SVM)-clustering-MNIST",
      "provenance": [],
      "collapsed_sections": [
        "pagnIXfpWgiW",
        "tY5fFCfHW4Xu",
        "CBhHMLWPW_50"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswarth123/Federated_Learning_Parameter_Clustering/blob/main/FederatedLearning(SVM)_clustering_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "mrM-uos6Bmn8",
        "outputId": "65c014de-a387-4bae-e25e-e1d7f64c56b7"
      },
      "source": [
        "!pip install fuzzy-c-means"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzy-c-means\n",
            "  Downloading fuzzy_c_means-1.6.3-py3-none-any.whl (9.1 kB)\n",
            "Collecting typer<0.4.0,>=0.3.2\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting pydantic<2.0.0,>=1.8.2\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.8.9)\n",
            "Collecting numpy<2.0.0,>=1.21.1\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 59 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.8.2->fuzzy-c-means) (3.10.0.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->fuzzy-c-means) (7.1.2)\n",
            "Installing collected packages: typer, pydantic, numpy, fuzzy-c-means\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fuzzy-c-means-1.6.3 numpy-1.21.4 pydantic-1.8.2 typer-0.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1itX_EqWSNg"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "from fcmeans import FCM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ6brHdoWnFA"
      },
      "source": [
        "# All Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pagnIXfpWgiW"
      },
      "source": [
        "## SVM Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0IFXh4zWcwF"
      },
      "source": [
        "class SVM:\n",
        "\n",
        "  def __init__(self, X_train, y_train, X_test, y_test, val=True, val_type='k_fold', k=5, opt='mini_batch_GD', batch_size = 30, n_iters=100, learning_rate=0.001, lambda_param=0.01):\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "\n",
        "    self.val = val\n",
        "    self.val_type=val_type\n",
        "    self.k=k\n",
        "\n",
        "    self.opt = opt\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.w = np.array([])\n",
        "    self.b = None\n",
        "\n",
        "  def grad(self,x,y):\n",
        "    if y * (np.dot(x, self.w) - self.b) >= 1:\n",
        "      dw = self.lr * (2 * self.lambda_param * self.w)\n",
        "      db = 0\n",
        "    else:\n",
        "      dw = self.lr * (2 * self.lambda_param * self.w - np.dot(x, y))\n",
        "      db = self.lr * y\n",
        "\n",
        "    return (dw,db)\n",
        "  \n",
        "\n",
        "  def stochastic_GD(self, X_train, y_train, X_val=None, y_val=None):\n",
        "    n_samples, n_features = X_train.shape  \n",
        "    y_ = np.where(y_train <= 0, -1, 1)\n",
        "          \n",
        "    if self.w.size == 0 and self.b is None :\n",
        "      self.w = np.zeros(n_features)\n",
        "      self.b = 0\n",
        "\n",
        "    w_best = np.zeros(n_features)\n",
        "    b_best = 0\n",
        "\n",
        "    acc_list = [] \n",
        "    for i in range(0,self.n_iters):\n",
        "      for idx, x_i in enumerate(X_train):\n",
        "        dw,db = self.grad(x_i,y_[idx])\n",
        "        self.w -= dw\n",
        "        self.b -= db\n",
        "    \n",
        "      if i%10 == 0 and self.val:\n",
        "        approx_w = np.dot(X_val, self.w) - self.b\n",
        "        approx_w = np.sign(approx_w)\n",
        "        res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "        approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "        approx_w_best = np.sign(approx_w_best)\n",
        "        res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "            \n",
        "        if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "          w_best = copy.deepcopy(self.w)\n",
        "          b_best = copy.deepcopy(self.b)\n",
        "\n",
        "\n",
        "  def batch_GD(self, X_train, y_train, X_val=None, y_val=None):\n",
        "      n_samples, n_features = X_train.shape  \n",
        "      y_ = np.where(y_train <= 0, -1, 1)\n",
        "            \n",
        "      if self.w.size == 0 and self.b is None :\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "      w_best = np.zeros(n_features)\n",
        "      b_best = 0\n",
        "\n",
        "      acc_list = [] \n",
        "      for i in range(0,self.n_iters):\n",
        "        dw_sum=0\n",
        "        db_sum=0\n",
        "        for idx, x_i in enumerate(X_train):\n",
        "          dw,db = self.grad(x_i,y_[idx])\n",
        "          dw_sum+=dw\n",
        "          db_sum+=db\n",
        "        self.w -= (dw_sum/n_samples)\n",
        "        self.b -= (db_sum/n_samples)\n",
        "      \n",
        "        if i%10 == 0 and self.val:\n",
        "          approx_w = np.dot(X_val, self.w) - self.b\n",
        "          approx_w = np.sign(approx_w)\n",
        "          res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "          approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "          approx_w_best = np.sign(approx_w_best)\n",
        "          res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "              \n",
        "          if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "            w_best = copy.deepcopy(self.w)\n",
        "            b_best = copy.deepcopy(self.b)\n",
        "\n",
        "\n",
        "  def mini_batch_GD(self, X_train, y_train, X_val=None, y_val=None):\n",
        "      n_samples, n_features = X_train.shape  \n",
        "      y_ = np.where(y_train <= 0, -1, 1)\n",
        "            \n",
        "      if self.w.size == 0 and self.b is None :\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "      w_best = np.zeros(n_features)\n",
        "      b_best = 0\n",
        "\n",
        "      acc_list = [] \n",
        "\n",
        "      # print(self.n_iters)\n",
        "      \n",
        "      for i in range(0,self.n_iters):\n",
        "        # print(i)\n",
        "        dw_sum=0.0\n",
        "        db_sum=0.0\n",
        "        s=0\n",
        "        for idx, x_i in enumerate(X_train):\n",
        "          dw,db = self.grad(x_i,y_[idx])\n",
        "          dw_sum+=dw\n",
        "          db_sum+=db\n",
        "          s += 1\n",
        "          if s%self.batch_size==0:\n",
        "            self.w -= (dw_sum/self.batch_size)\n",
        "            self.b -= (db_sum/self.batch_size)\n",
        "      \n",
        "        if i%10 == 0 and self.val:\n",
        "          approx_w = np.dot(X_val, self.w) - self.b\n",
        "          approx_w = np.sign(approx_w)\n",
        "          res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "          approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "          approx_w_best = np.sign(approx_w_best)\n",
        "          res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "              \n",
        "          if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "            w_best = copy.deepcopy(self.w)\n",
        "            b_best = copy.deepcopy(self.b)\n",
        "\n",
        "\n",
        "  def cross_validation(self, val_split):\n",
        "\n",
        "    X_train = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "    y_train = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split, random_state=1, stratify=y_train)\n",
        "\n",
        "    eval(\"self.\"+self.opt+\"(X_train, y_train, X_val, y_val)\")\n",
        "\n",
        "\n",
        "  def k_fold_cross_validation(self):\n",
        "\n",
        "    X = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "    y = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "\n",
        "    w_list = []\n",
        "    b_list = []\n",
        "    acc_list = []\n",
        "\n",
        "    if self.w.size == 0 and self.b == None:\n",
        "      w = np.zeros(self.X_train[0].shape[1])\n",
        "      b = 0\n",
        "    else:\n",
        "      w = copy.deepcopy(self.w)\n",
        "      b = self.b\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=self.k, shuffle=True)\n",
        "\n",
        "    for train_index, val_index in skf.split(X,y):\n",
        "      \n",
        "      X_train, X_val = X[train_index], X[val_index]\n",
        "      y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "      eval(\"self.\"+self.opt+\"(X_train, y_train, X_val, y_val)\")\n",
        "\n",
        "      print(self.accuracy())\n",
        "      w_list.append(self.w)\n",
        "      b_list.append(self.b)\n",
        "\n",
        "      test_w = np.dot(X_val, self.w) - self.b\n",
        "      test_w = np.sign(test_w)\n",
        "      res_val = np.where(test_w<0,0,test_w)\n",
        "\n",
        "      acc_list.append(accuracy_score(y_val, res_val))\n",
        "    \n",
        "      self.w = copy.deepcopy(w)\n",
        "      self.b = b\n",
        "\n",
        "    self.w = copy.deepcopy(w_list[acc_list.index(max(acc_list))])\n",
        "    self.b = b_list[acc_list.index(max(acc_list))]\n",
        "  \n",
        "\n",
        "  def fit(self):\n",
        "    if self.val_type == 'k_fold' and self.val:\n",
        "      self.k_fold_cross_validation()\n",
        "    \n",
        "    elif self.val_type == 'cross_val' and self.val:\n",
        "      self.cross_validation(0.2)\n",
        "    \n",
        "    elif not self.val:\n",
        "      X_train = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "      y_train = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "      X_train, y_train= shuffle(X_train, y_train)\n",
        "      eval(\"self.\"+self.opt+\"(X_train, y_train)\")\n",
        "\n",
        "  def predict(self):\n",
        "     approx = np.dot(self.X_test, self.w) - self.b\n",
        "     approx = np.sign(approx)\n",
        "     return np.where(approx<0, 0, approx)\n",
        "\n",
        "  def accuracy(self):\n",
        "    return accuracy_score(self.y_test, self.predict())*100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5fFCfHW4Xu"
      },
      "source": [
        "## Federated Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57k98FPuWz-t"
      },
      "source": [
        "class Federated_SVM:\n",
        "\n",
        "  def __init__(self, n_clients=5, val=True, val_type='k_fold', k=5, opt='mini_batch_GD', batch_size = 30, learning_rate=0.001, lambda_param=0.01, n_iters=100):\n",
        "    self.n_clients = n_clients\n",
        "    self.learning_rate = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "    self.val = val\n",
        "    self.val_type = val_type\n",
        "    self.client_distribution = []\n",
        "    self.k = k\n",
        "    self.opt = opt\n",
        "    self.batch_size = batch_size\n",
        "    self.X_test = None\n",
        "    self.y_test = None\n",
        "    self.X_clients_test = None\n",
        "    self.y_clients_test = None\n",
        "\n",
        "  def create_clients(self, X_train, y_train, X_clients_test, y_clients_test, X_test, y_test):\n",
        "    self.clients=[]\n",
        "    for i in range(self.n_clients):\n",
        "      self.client_distribution.append(X_train[i][0].shape[0] + X_train[i][1].shape[0])\n",
        "      self.clients.append(SVM(X_train[i],y_train[i], np.concatenate(X_clients_test[i],axis=0), np.concatenate(y_clients_test[i],axis=0), self.val, self.val_type, self.k, self.opt, self.batch_size, self.n_iters, self.learning_rate, self.lambda_param))\n",
        "    self.X_test = copy.deepcopy(X_test)\n",
        "    self.y_test = copy.deepcopy(y_test)\n",
        "  \n",
        "\n",
        "  def average_aggregator(self, parameter_list):\n",
        "    w = np.zeros(parameter_list[0].shape[0])\n",
        "    b = 0\n",
        "    for i in range(0,2*self.n_clients,2):\n",
        "        w = np.add(w,parameter_list[i]*self.client_distribution[i//2]/sum(self.client_distribution))\n",
        "        b = b + parameter_list[i+1]*self.client_distribution[i//2]/sum(self.client_distribution)\n",
        "    return (w, b)\n",
        "\n",
        "  def highest_aggregator(self, parameter_list):\n",
        "    score = 0\n",
        "\n",
        "    for i in range(0,self.n_clients):\n",
        "      acc = self.clients[i].accuracy()\n",
        "      if (acc > score):\n",
        "        w = copy.deepcopy(self.clients[i].w)\n",
        "        b = self.clients[i].b\n",
        "        acc = score\n",
        "\n",
        "    return (w,b)\n",
        "\n",
        "  def random_aggregator(self,parameter_list):\n",
        "    n = random.randint(0,self.n_clients)\n",
        "    w = np.zeros(parameter_list[0].shape[0])\n",
        "    b = 0\n",
        "    for i in range(0,2*self.n_clients,2):\n",
        "      if i//2 != n:\n",
        "        w = np.add(w,parameter_list[i]*self.client_distribution[i//2]/sum(self.client_distribution))\n",
        "        b = b + parameter_list[i+1]*self.client_distribution[i//2]/sum(self.client_distribution)\n",
        "      else:\n",
        "        continue\n",
        "    return (w, b)\n",
        "\n",
        "  def adaptive_scaling_aggregator(self, parameter_list):\n",
        "      clus_param = parameter_list[0]\n",
        "      for i in range(2,len(parameter_list),2):\n",
        "        clus_param = np.row_stack((clus_param,parameter_list[i]))\n",
        "\n",
        "      # print(clus_param)\n",
        "      \n",
        "      fcm = FCM(n_clusters=3)\n",
        "      fcm.fit(clus_param)\n",
        "      res = fcm.predict(clus_param)\n",
        "      prob = fcm.soft_predict(clus_param)\n",
        "      \n",
        "      clus_weights=[]\n",
        "\n",
        "      for i in range(0,3):\n",
        "        sw = np.zeros(len(parameter_list[0]))\n",
        "        sb=0\n",
        "        for j in range(0,len(parameter_list),2):\n",
        "          sw += parameter_list[j]*prob[j//2][i]\n",
        "          sb += parameter_list[j+1]*prob[j//2][i]\n",
        "        \n",
        "\n",
        "        clus_weights.append(sw/np.sum(prob[:][i]))\n",
        "        clus_weights.append(sb/np.sum(prob[:][i]))\n",
        "\n",
        "      for i in range(0,self.n_clients):\n",
        "        \n",
        "        self.clients[i].w = copy.deepcopy(clus_weights[2*res[i]])\n",
        "        self.clients[i].b = copy.deepcopy(clus_weights[2*res[i]+1])\n",
        "\n",
        "      print(prob)\n",
        "      if res[0]==res[3]:\n",
        "        print(\"clus 1 true\")\n",
        "      else:\n",
        "        print(\"clus 1 flase\")\n",
        "\n",
        "      if res[1]==res[4]:\n",
        "        print(\"clus 2 true\")\n",
        "      else:\n",
        "        print(\"clus 2 flase\")\n",
        "        print('global test acc',self.accuracy(w_best,b_best))\n",
        "      \n",
        "      return(self.average_aggregator(parameter_list))\n",
        "\n",
        "    \n",
        "      \n",
        "  def fit(self, g_iters, aggregator):\n",
        "    w_best = np.zeros(self.X_test.shape[1])\n",
        "    b_best = 0\n",
        "    for i in range(0,g_iters):\n",
        "      print('global round',i+1)\n",
        "      for j in range(0,self.n_clients):\n",
        "        if i==0 or aggregator == self.adaptive_scaling_aggregator:\n",
        "          self.clients[j].fit()\n",
        "        else:\n",
        "          self.clients[j].w = copy.deepcopy(w_agg)\n",
        "          self.clients[j].b = copy.deepcopy(b_agg)\n",
        "          self.clients[j].fit()\n",
        "        print('client',j+1,self.clients[j].accuracy())          \n",
        "      parameter_list = []\n",
        "      for k in range(0,self.n_clients):\n",
        "        parameter_list.append(self.clients[k].w)\n",
        "        parameter_list.append(self.clients[k].b)\n",
        "        # print(\"client\",k,self.clients[k].w+[self.clients[k].b])\n",
        "      \n",
        "      w_agg, b_agg = aggregator(parameter_list)\n",
        "      # print(\"agg\",self.accuracy(w_agg,b_agg),\"best\",self.accuracy(w_best,b_best))\n",
        "      if self.accuracy(w_agg,b_agg)>self.accuracy(w_best,b_best) or i==0:\n",
        "        w_best=copy.deepcopy(w_agg)\n",
        "        b_best=copy.deepcopy(b_agg)\n",
        "      print('global test acc',self.accuracy(w_best,b_best))\n",
        "\n",
        "\n",
        "  def predict(self,w,b):\n",
        "     approx = np.dot(self.X_test, w) - b\n",
        "     approx = np.sign(approx)\n",
        "     return np.where(approx<0, 0, 1)\n",
        "  \n",
        "  def accuracy(self,w,b):\n",
        "    return accuracy_score(self.y_test, self.predict(w,b))*100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhHMLWPW_50"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBaGyMvsXDc_"
      },
      "source": [
        "def create_kmeans_clusters(X, Y, n_clusters = 3, random_state = 0):\n",
        "  clusters = KMeans(n_clusters=n_clusters, random_state=random_state).fit_predict(X)\n",
        "  result = []\n",
        "  for i in range(n_clusters):\n",
        "    result.append(X[clusters == i])\n",
        "    result.append(Y[clusters == i])\n",
        "  return tuple(result)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3eGAEXtXFaM"
      },
      "source": [
        "def get_clients(class1, class2, n_clusters = 3, n_clients = 5):\n",
        "\n",
        "  clients_X = []\n",
        "  clients_y = []\n",
        "\n",
        "  clientsXtest = []\n",
        "  clientsYtest = []\n",
        "\n",
        "  X_test = []\n",
        "  y_test = []\n",
        "\n",
        "  clusters_1 = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(class1)\n",
        "  clusters_2 = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(class2)\n",
        "\n",
        "  for i in range(n_clusters):\n",
        "\n",
        "    X_train0, X_test0, y_train0, y_test0 = train_test_split(class1[clusters_1 == i],np.zeros((class1[clusters_1 == i].shape[0],)),test_size=0.2)\n",
        "    X_train1, X_test1, y_train1, y_test1 = train_test_split(class2[clusters_2 == i],np.ones((class2[clusters_2 == i].shape[0],)),test_size=0.2)\n",
        "\n",
        "    clients_X.append([X_train0, X_train1])\n",
        "    clients_y.append([y_train0, y_train1])\n",
        "\n",
        "    clientsXtest.append([X_test0,X_test1])\n",
        "    clientsYtest.append([y_test0,y_test1])\n",
        "\n",
        "    X_test.extend([X_test0,X_test1])\n",
        "    y_test.extend([y_test0,y_test1])\n",
        "\n",
        "  for i in range(0,2):\n",
        "    X_train0_ex, X_test0_ex, y_train0_ex, y_test0_ex = train_test_split(clients_X[i][0],clients_y[i][0],test_size=0.5)\n",
        "    X_train1_ex, X_test1_ex, y_train1_ex, y_test1_ex = train_test_split(clients_X[i][1],clients_y[i][1],test_size=0.5)\n",
        "\n",
        "    clients_X.append([X_train0_ex, X_train1_ex])\n",
        "    clients_y.append([y_train0_ex, y_train1_ex])\n",
        "\n",
        "    clients_X[i][0],clients_y[i][0] = copy.deepcopy(X_test0_ex), copy.deepcopy(y_test0_ex)\n",
        "    clients_X[i][1],clients_y[i][1] = copy.deepcopy(X_test1_ex), copy.deepcopy(y_test1_ex)\n",
        "\n",
        "    X_train0_exte, X_test0_exte, y_train0_exte, y_test0_exte = train_test_split(clientsXtest[i][0],clientsYtest[i][0],test_size=0.5)\n",
        "    X_train1_exte, X_test1_exte, y_train1_exte, y_test1_exte = train_test_split(clientsXtest[i][1],clientsYtest[i][1],test_size=0.5)    \n",
        "\n",
        "    clientsXtest.append([X_train0_exte, X_train1_exte])\n",
        "    clientsYtest.append([y_train0_exte, y_train1_exte])\n",
        "\n",
        "    clientsXtest[i][0],clientsYtest[i][0] = copy.deepcopy(X_test0_exte), copy.deepcopy(y_test0_exte)\n",
        "    clientsXtest[i][1],clientsYtest[i][1] = copy.deepcopy(X_test1_exte), copy.deepcopy(y_test1_exte)\n",
        "\n",
        "    X_test.extend([X_test0_exte,X_test1_exte])\n",
        "    y_test.extend([y_test0_exte,y_test1_exte])\n",
        "\n",
        "  X_test = np.concatenate(X_test,axis=0)\n",
        "  y_test = np.concatenate(y_test,axis=0)\n",
        "\n",
        "  return clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLKYcboEKMn-"
      },
      "source": [
        "def load_mnist_return_required_digits(n1, n2):\n",
        "  # Loading the mnist dataset and concatenating train - test sets\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  x_total = np.concatenate((x_train, x_test), axis=0)\n",
        "  y_total = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "  # Normalizing and reshaping the data\n",
        "  x_total = x_total/255 \n",
        "  x_total = x_total.reshape(x_total.shape[0],784)\n",
        "\n",
        "  x_n1 = x_total[y_total == n1]\n",
        "  y_n1 = y_total[y_total == n1]\n",
        "\n",
        "  x_n2 = x_total[y_total == n2]\n",
        "  y_n2 = y_total[y_total == n2]\n",
        "\n",
        "  return [(x_n1, y_n1),(x_n2, y_n2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeEDnNPfXKig"
      },
      "source": [
        "def get_total_from_clients(clients_X,clients_y):\n",
        "  x_train0 = [i[0] for i in clients_X]\n",
        "  x_train0 = np.concatenate(x_train0, axis=0)\n",
        "  x_train1 = [i[1] for i in clients_X]\n",
        "  x_train1 = np.concatenate(x_train1, axis=0)\n",
        "  y_train0 = [i[0] for i in clients_y]\n",
        "  y_train0 = np.concatenate(y_train0, axis=0)\n",
        "  y_train1 = [i[1] for i in clients_y]\n",
        "  y_train1 = np.concatenate(y_train1, axis=0)\n",
        "\n",
        "  return ([x_train0,x_train1],[y_train0,y_train1])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1WJlkhSKshA"
      },
      "source": [
        "# MNIST 0 & 6\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09thAD_gtuBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53673f86-c445-41fc-b4e9-e435f3203b86"
      },
      "source": [
        "mnist = load_mnist_return_required_digits(0,6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ozlcGrKuos"
      },
      "source": [
        "clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test = get_clients(mnist[0][0], mnist[1][0], n_clusters = 3, n_clients = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExGr-AZgLAR2"
      },
      "source": [
        "xtrain_gl, ytrain_gl = get_total_from_clients(clients_X,clients_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM-lmSEaLEm5"
      },
      "source": [
        "f_svm = Federated_SVM(n_clients = 5, val=False, n_iters=150,opt='stochastic_GD')\n",
        "f_svm.create_clients(clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Xfk0DGLJNF",
        "outputId": "ca3ae615-59fa-463e-bcf6-6a17a75f5e3b"
      },
      "source": [
        "f_svm.fit(10,f_svm.adaptive_scaling_aggregator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global round 1\n",
            "client 1 98.91540130151843\n",
            "client 2 99.79797979797979\n",
            "client 3 99.76387249114522\n",
            "client 4 99.13232104121475\n",
            "client 5 99.59514170040485\n",
            "[[7.04045049e-01 1.27255242e-01 1.68699709e-01]\n",
            " [4.11825324e-02 6.58187974e-02 8.92998670e-01]\n",
            " [5.52225408e-04 9.98362366e-01 1.08540906e-03]\n",
            " [8.57934757e-01 6.43358492e-02 7.77293941e-02]\n",
            " [4.36811344e-02 6.33365842e-02 8.92982281e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.71136241249326\n",
            "global round 2\n",
            "client 1 99.13232104121475\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.34924078091106\n",
            "client 5 99.59514170040485\n",
            "[[1.47661178e-01 1.12554391e-01 7.39784431e-01]\n",
            " [8.88446801e-01 6.72065571e-02 4.43466419e-02]\n",
            " [8.65746825e-04 9.98669211e-01 4.65042040e-04]\n",
            " [8.93453391e-02 7.24189103e-02 8.38235751e-01]\n",
            " [8.85774541e-01 6.52033499e-02 4.90221093e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 3\n",
            "client 1 98.69848156182212\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.56616052060737\n",
            "client 5 99.59514170040485\n",
            "[[1.54057152e-01 1.13280519e-01 7.32662329e-01]\n",
            " [8.88922331e-01 6.76970896e-02 4.33805795e-02]\n",
            " [8.71944590e-04 9.98683127e-01 4.44928222e-04]\n",
            " [8.64371428e-02 6.83448474e-02 8.45218010e-01]\n",
            " [8.87796591e-01 6.44373108e-02 4.77660985e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 4\n",
            "client 1 98.69848156182212\n",
            "client 2 99.79797979797979\n",
            "client 3 99.76387249114522\n",
            "client 4 99.56616052060737\n",
            "client 5 99.79757085020243\n",
            "[[1.49629354e-01 1.13040595e-01 7.37330051e-01]\n",
            " [8.87524147e-01 6.89594492e-02 4.35164038e-02]\n",
            " [9.45577669e-04 9.98569602e-01 4.84820304e-04]\n",
            " [8.78817053e-02 7.29628957e-02 8.39155399e-01]\n",
            " [8.82560060e-01 6.90005578e-02 4.84393823e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 5\n",
            "client 1 98.91540130151843\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.56616052060737\n",
            "client 5 99.79757085020243\n",
            "[[7.37471972e-01 1.13202302e-01 1.49325727e-01]\n",
            " [3.91744676e-02 5.88678453e-02 9.01957687e-01]\n",
            " [3.82635262e-04 9.98893779e-01 7.23585815e-04]\n",
            " [8.59376630e-01 6.32043900e-02 7.74189801e-02]\n",
            " [4.32364345e-02 6.07167422e-02 8.96046823e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 6\n",
            "client 1 98.91540130151843\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.56616052060737\n",
            "client 5 99.79757085020243\n",
            "[[0.99146633 0.00316584 0.00536784]\n",
            " [0.05303577 0.90097153 0.0459927 ]\n",
            " [0.21404492 0.59407753 0.19187755]\n",
            " [0.00375602 0.00191822 0.99432576]\n",
            " [0.06740876 0.87726089 0.05533035]]\n",
            "clus 1 flase\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 7\n",
            "client 1 99.13232104121475\n",
            "client 2 100.0\n",
            "client 3 99.76387249114522\n",
            "client 4 99.34924078091106\n",
            "client 5 99.59514170040485\n",
            "[[7.67807670e-01 1.28829031e-01 1.03363300e-01]\n",
            " [3.25363852e-02 9.14357015e-01 5.31065994e-02]\n",
            " [3.23298175e-04 6.01498030e-04 9.99075204e-01]\n",
            " [8.47575353e-01 8.01241906e-02 7.23004559e-02]\n",
            " [3.63032153e-02 9.10300985e-01 5.33957995e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 8\n",
            "client 1 98.91540130151843\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.34924078091106\n",
            "client 5 99.79757085020243\n",
            "[[1.11884433e-01 7.52176189e-01 1.35939378e-01]\n",
            " [5.52064971e-02 3.53356807e-02 9.09457822e-01]\n",
            " [9.98954335e-01 3.80964079e-04 6.64700548e-04]\n",
            " [6.88858483e-02 8.54559036e-01 7.65551162e-02]\n",
            " [5.56442023e-02 4.02431622e-02 9.04112635e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 9\n",
            "client 1 99.13232104121475\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.13232104121475\n",
            "client 5 99.59514170040485\n",
            "[[1.35487600e-01 7.50453247e-01 1.14059154e-01]\n",
            " [9.09589655e-01 3.66065420e-02 5.38038028e-02]\n",
            " [7.18983629e-04 4.26645060e-04 9.98854371e-01]\n",
            " [8.05409224e-02 8.47456245e-01 7.20028330e-02]\n",
            " [8.96148497e-01 4.35293924e-02 6.03221111e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n",
            "global round 10\n",
            "client 1 98.91540130151843\n",
            "client 2 100.0\n",
            "client 3 99.64580873671783\n",
            "client 4 99.78308026030369\n",
            "client 5 99.59514170040485\n",
            "[[1.26240452e-01 7.66908395e-01 1.06851153e-01]\n",
            " [9.15194428e-01 3.39967759e-02 5.08087958e-02]\n",
            " [6.02941454e-04 3.71022984e-04 9.99026036e-01]\n",
            " [7.99431432e-02 8.44714038e-01 7.53428191e-02]\n",
            " [9.03440741e-01 4.10345867e-02 5.55246721e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 97.81906300484653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHHGx723eZkT"
      },
      "source": [
        "# MNIST 3 & 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0hArwesdjSu"
      },
      "source": [
        "mnist = load_mnist_return_required_digits(3,8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXqNt3njdcIQ"
      },
      "source": [
        "clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test = get_clients(mnist[0][0], mnist[1][0], n_clusters = 3, n_clients = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Osb_mVduD6"
      },
      "source": [
        "f_svm = Federated_SVM(n_clients = 5, val=False, n_iters=150,opt='stochastic_GD')\n",
        "f_svm.create_clients(clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q074_Jydx6S",
        "outputId": "3f56eadb-f317-429d-9fbd-2dcf11d3511b"
      },
      "source": [
        "f_svm.fit(10,f_svm.adaptive_scaling_aggregator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global round 1\n",
            "client 1 95.87155963302753\n",
            "client 2 98.77800407331976\n",
            "client 3 100.0\n",
            "client 4 98.61751152073732\n",
            "client 5 99.18533604887983\n",
            "[[1.12446027e-01 1.26728754e-01 7.60825218e-01]\n",
            " [8.63201292e-01 8.32037391e-02 5.35949692e-02]\n",
            " [1.38578296e-03 9.97729508e-01 8.84708755e-04]\n",
            " [9.18483000e-02 8.98701418e-02 8.18281558e-01]\n",
            " [8.52068807e-01 9.15654783e-02 5.63657149e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.32509403546482\n",
            "global round 2\n",
            "client 1 95.87155963302753\n",
            "client 2 98.77800407331976\n",
            "client 3 100.0\n",
            "client 4 98.15668202764977\n",
            "client 5 98.16700610997964\n",
            "[[9.58674266e-02 7.97701508e-01 1.06431066e-01]\n",
            " [8.54825849e-01 5.55884673e-02 8.95856835e-02]\n",
            " [1.17585605e-03 7.16320159e-04 9.98107824e-01]\n",
            " [9.90076483e-02 8.05903985e-01 9.50883671e-02]\n",
            " [8.58247719e-01 5.29434839e-02 8.88087970e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.32509403546482\n",
            "global round 3\n",
            "client 1 95.87155963302753\n",
            "client 2 98.98167006109979\n",
            "client 3 100.0\n",
            "client 4 98.15668202764977\n",
            "client 5 98.37067209775967\n",
            "[[9.89606168e-02 8.11358525e-01 8.96808584e-02]\n",
            " [8.29475288e-02 4.94701792e-02 8.67582292e-01]\n",
            " [9.98529894e-01 5.48110649e-04 9.21995351e-04]\n",
            " [9.01038162e-02 8.16735764e-01 9.31604196e-02]\n",
            " [8.36472946e-02 4.92331960e-02 8.67119509e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.40569586243954\n",
            "global round 4\n",
            "client 1 95.64220183486239\n",
            "client 2 98.77800407331976\n",
            "client 3 100.0\n",
            "client 4 98.38709677419355\n",
            "client 5 98.77800407331976\n",
            "[[8.43290074e-02 8.20875528e-01 9.47954646e-02]\n",
            " [8.69587086e-01 4.70777648e-02 8.33351496e-02]\n",
            " [9.72858472e-04 5.50559257e-04 9.98476582e-01]\n",
            " [9.70997513e-02 8.08327089e-01 9.45731594e-02]\n",
            " [8.65286892e-01 4.76692791e-02 8.70438287e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n",
            "global round 5\n",
            "client 1 95.87155963302753\n",
            "client 2 98.77800407331976\n",
            "client 3 100.0\n",
            "client 4 98.38709677419355\n",
            "client 5 98.37067209775967\n",
            "[[8.07229976e-01 8.98955212e-02 1.02874503e-01]\n",
            " [4.51701946e-02 8.71794379e-01 8.30354263e-02]\n",
            " [5.43749742e-04 1.00507471e-03 9.98451176e-01]\n",
            " [8.23534261e-01 8.90502514e-02 8.74154874e-02]\n",
            " [4.50985553e-02 8.67150641e-01 8.77508041e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n",
            "global round 6\n",
            "client 1 95.64220183486239\n",
            "client 2 99.18533604887983\n",
            "client 3 100.0\n",
            "client 4 98.38709677419355\n",
            "client 5 98.57433808553971\n",
            "[[0.00252373 0.99166744 0.00580883]\n",
            " [0.88577255 0.05588151 0.05834594]\n",
            " [0.57993378 0.21812029 0.20194592]\n",
            " [0.00219433 0.00477235 0.99303332]\n",
            " [0.8875083  0.05391116 0.05858053]]\n",
            "clus 1 flase\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n",
            "global round 7\n",
            "client 1 95.87155963302753\n",
            "client 2 98.98167006109979\n",
            "client 3 100.0\n",
            "client 4 98.15668202764977\n",
            "client 5 98.37067209775967\n",
            "[[8.06028652e-01 1.02844664e-01 9.11266838e-02]\n",
            " [4.84180600e-02 8.41325381e-02 8.67449402e-01]\n",
            " [6.37173304e-04 9.98246830e-01 1.11599627e-03]\n",
            " [8.10793342e-01 9.34650525e-02 9.57416058e-02]\n",
            " [5.08819043e-02 9.30318863e-02 8.56086209e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n",
            "global round 8\n",
            "client 1 95.87155963302753\n",
            "client 2 98.98167006109979\n",
            "client 3 100.0\n",
            "client 4 98.15668202764977\n",
            "client 5 98.77800407331976\n",
            "[[8.75912563e-02 1.02251273e-01 8.10157470e-01]\n",
            " [8.63972060e-01 8.70695123e-02 4.89584276e-02]\n",
            " [1.09498116e-03 9.98272739e-01 6.32280260e-04]\n",
            " [9.51064940e-02 9.37166774e-02 8.11176829e-01]\n",
            " [8.59701606e-01 9.06490902e-02 4.96493037e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n",
            "global round 9\n",
            "client 1 95.87155963302753\n",
            "client 2 98.77800407331976\n",
            "client 3 100.0\n",
            "client 4 98.38709677419355\n",
            "client 5 98.57433808553971\n",
            "[[8.27749805e-01 9.25887742e-02 7.96614207e-02]\n",
            " [4.67155228e-02 8.87694095e-02 8.64515068e-01]\n",
            " [4.87962011e-04 9.98613522e-01 8.98516285e-04]\n",
            " [8.26368260e-01 8.64665332e-02 8.71652064e-02]\n",
            " [4.61508070e-02 8.90849930e-02 8.64764200e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n",
            "global round 10\n",
            "client 1 95.87155963302753\n",
            "client 2 98.98167006109979\n",
            "client 3 100.0\n",
            "client 4 97.92626728110599\n",
            "client 5 98.57433808553971\n",
            "[[0.99194415 0.00570074 0.0023551 ]\n",
            " [0.05545464 0.06037676 0.88416861]\n",
            " [0.21457919 0.20362476 0.58179605]\n",
            " [0.00508371 0.99261252 0.00230376]\n",
            " [0.05213318 0.05902976 0.88883705]]\n",
            "clus 1 flase\n",
            "clus 2 true\n",
            "global test acc 95.45943041375604\n"
          ]
        }
      ]
    }
  ]
}