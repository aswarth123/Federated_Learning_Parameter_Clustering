{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedLearning(SVM)-clustering-Paralysis",
      "provenance": [],
      "collapsed_sections": [
        "pagnIXfpWgiW",
        "tY5fFCfHW4Xu",
        "CBhHMLWPW_50"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswarth123/Federated_Learning_Parameter_Clustering/blob/main/FederatedLearning(SVM)_clustering_Paralysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "mrM-uos6Bmn8",
        "outputId": "c1cd5b4e-855c-4fa4-b28c-908753e2c4ba"
      },
      "source": [
        "!pip install fuzzy-c-means"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzy-c-means\n",
            "  Downloading fuzzy_c_means-1.6.3-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.8.9)\n",
            "Collecting typer<0.4.0,>=0.3.2\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Collecting pydantic<2.0.0,>=1.8.2\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 10.8 MB/s \n",
            "\u001b[?25hCollecting numpy<2.0.0,>=1.21.1\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 60 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.8.2->fuzzy-c-means) (3.10.0.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->fuzzy-c-means) (7.1.2)\n",
            "Installing collected packages: typer, pydantic, numpy, fuzzy-c-means\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fuzzy-c-means-1.6.3 numpy-1.21.4 pydantic-1.8.2 typer-0.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1itX_EqWSNg"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "from fcmeans import FCM"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ6brHdoWnFA"
      },
      "source": [
        "# All Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pagnIXfpWgiW"
      },
      "source": [
        "## SVM Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0IFXh4zWcwF"
      },
      "source": [
        "class SVM:\n",
        "\n",
        "  def __init__(self, X_train, y_train, X_test, y_test, val=True, val_type='k_fold', k=5, opt='mini_batch_GD', batch_size = 30, n_iters=100, learning_rate=0.001, lambda_param=0.01):\n",
        "\n",
        "    self.lr = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "\n",
        "    self.X_test = X_test\n",
        "    self.y_test = y_test\n",
        "\n",
        "    self.val = val\n",
        "    self.val_type=val_type\n",
        "    self.k=k\n",
        "\n",
        "    self.opt = opt\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.w = np.array([])\n",
        "    self.b = None\n",
        "\n",
        "  def grad(self,x,y):\n",
        "    if y * (np.dot(x, self.w) - self.b) >= 1:\n",
        "      dw = self.lr * (2 * self.lambda_param * self.w)\n",
        "      db = 0\n",
        "    else:\n",
        "      dw = self.lr * (2 * self.lambda_param * self.w - np.dot(x, y))\n",
        "      db = self.lr * y\n",
        "\n",
        "    return (dw,db)\n",
        "  \n",
        "\n",
        "  def stochastic_GD(self, X_train, y_train, X_val=None, y_val=None):\n",
        "    n_samples, n_features = X_train.shape  \n",
        "    y_ = np.where(y_train <= 0, -1, 1)\n",
        "          \n",
        "    if self.w.size == 0 and self.b is None :\n",
        "      self.w = np.zeros(n_features)\n",
        "      self.b = 0\n",
        "\n",
        "    w_best = np.zeros(n_features)\n",
        "    b_best = 0\n",
        "\n",
        "    acc_list = [] \n",
        "    for i in range(0,self.n_iters):\n",
        "      for idx, x_i in enumerate(X_train):\n",
        "        dw,db = self.grad(x_i,y_[idx])\n",
        "        self.w -= dw\n",
        "        self.b -= db\n",
        "    \n",
        "      if i%10 == 0 and self.val:\n",
        "        approx_w = np.dot(X_val, self.w) - self.b\n",
        "        approx_w = np.sign(approx_w)\n",
        "        res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "        approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "        approx_w_best = np.sign(approx_w_best)\n",
        "        res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "            \n",
        "        if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "          w_best = copy.deepcopy(self.w)\n",
        "          b_best = copy.deepcopy(self.b)\n",
        "\n",
        "\n",
        "  def batch_GD(self, X_train, y_train, X_val=None, y_val=None):\n",
        "      n_samples, n_features = X_train.shape  \n",
        "      y_ = np.where(y_train <= 0, -1, 1)\n",
        "            \n",
        "      if self.w.size == 0 and self.b is None :\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "      w_best = np.zeros(n_features)\n",
        "      b_best = 0\n",
        "\n",
        "      acc_list = [] \n",
        "      for i in range(0,self.n_iters):\n",
        "        dw_sum=0\n",
        "        db_sum=0\n",
        "        for idx, x_i in enumerate(X_train):\n",
        "          dw,db = self.grad(x_i,y_[idx])\n",
        "          dw_sum+=dw\n",
        "          db_sum+=db\n",
        "        self.w -= (dw_sum/n_samples)\n",
        "        self.b -= (db_sum/n_samples)\n",
        "      \n",
        "        if i%10 == 0 and self.val:\n",
        "          approx_w = np.dot(X_val, self.w) - self.b\n",
        "          approx_w = np.sign(approx_w)\n",
        "          res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "          approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "          approx_w_best = np.sign(approx_w_best)\n",
        "          res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "              \n",
        "          if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "            w_best = copy.deepcopy(self.w)\n",
        "            b_best = copy.deepcopy(self.b)\n",
        "\n",
        "\n",
        "  def mini_batch_GD(self, X_train, y_train, X_val=None, y_val=None):\n",
        "      n_samples, n_features = X_train.shape  \n",
        "      y_ = np.where(y_train <= 0, -1, 1)\n",
        "            \n",
        "      if self.w.size == 0 and self.b is None :\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "      w_best = np.zeros(n_features)\n",
        "      b_best = 0\n",
        "\n",
        "      acc_list = [] \n",
        "\n",
        "      # print(self.n_iters)\n",
        "      \n",
        "      for i in range(0,self.n_iters):\n",
        "        # print(i)\n",
        "        dw_sum=0.0\n",
        "        db_sum=0.0\n",
        "        s=0\n",
        "        for idx, x_i in enumerate(X_train):\n",
        "          dw,db = self.grad(x_i,y_[idx])\n",
        "          dw_sum+=dw\n",
        "          db_sum+=db\n",
        "          s += 1\n",
        "          if s%self.batch_size==0:\n",
        "            self.w -= (dw_sum/self.batch_size)\n",
        "            self.b -= (db_sum/self.batch_size)\n",
        "      \n",
        "        if i%10 == 0 and self.val:\n",
        "          approx_w = np.dot(X_val, self.w) - self.b\n",
        "          approx_w = np.sign(approx_w)\n",
        "          res_w = np.where(approx_w<0, 0, approx_w)\n",
        "\n",
        "          approx_w_best = np.dot(X_val, w_best) - b_best\n",
        "          approx_w_best = np.sign(approx_w_best)\n",
        "          res_w_best = np.where(approx_w_best<0, 0, approx_w_best)\n",
        "              \n",
        "          if (accuracy_score(y_val, res_w_best) < accuracy_score(y_val, res_w)):\n",
        "            w_best = copy.deepcopy(self.w)\n",
        "            b_best = copy.deepcopy(self.b)\n",
        "\n",
        "\n",
        "  def cross_validation(self, val_split):\n",
        "\n",
        "    X_train = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "    y_train = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split, random_state=1, stratify=y_train)\n",
        "\n",
        "    eval(\"self.\"+self.opt+\"(X_train, y_train, X_val, y_val)\")\n",
        "\n",
        "\n",
        "  def k_fold_cross_validation(self):\n",
        "\n",
        "    X = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "    y = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "\n",
        "    w_list = []\n",
        "    b_list = []\n",
        "    acc_list = []\n",
        "\n",
        "    if self.w.size == 0 and self.b == None:\n",
        "      w = np.zeros(self.X_train[0].shape[1])\n",
        "      b = 0\n",
        "    else:\n",
        "      w = copy.deepcopy(self.w)\n",
        "      b = self.b\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=self.k, shuffle=True)\n",
        "\n",
        "    for train_index, val_index in skf.split(X,y):\n",
        "      \n",
        "      X_train, X_val = X[train_index], X[val_index]\n",
        "      y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "      eval(\"self.\"+self.opt+\"(X_train, y_train, X_val, y_val)\")\n",
        "\n",
        "      print(self.accuracy())\n",
        "      w_list.append(self.w)\n",
        "      b_list.append(self.b)\n",
        "\n",
        "      test_w = np.dot(X_val, self.w) - self.b\n",
        "      test_w = np.sign(test_w)\n",
        "      res_val = np.where(test_w<0,0,test_w)\n",
        "\n",
        "      acc_list.append(accuracy_score(y_val, res_val))\n",
        "    \n",
        "      self.w = copy.deepcopy(w)\n",
        "      self.b = b\n",
        "\n",
        "    self.w = copy.deepcopy(w_list[acc_list.index(max(acc_list))])\n",
        "    self.b = b_list[acc_list.index(max(acc_list))]\n",
        "  \n",
        "\n",
        "  def fit(self):\n",
        "    if self.val_type == 'k_fold' and self.val:\n",
        "      self.k_fold_cross_validation()\n",
        "    \n",
        "    elif self.val_type == 'cross_val' and self.val:\n",
        "      self.cross_validation(0.2)\n",
        "    \n",
        "    elif not self.val:\n",
        "      X_train = np.concatenate((self.X_train[0],self.X_train[1]),axis=0)\n",
        "      y_train = np.concatenate((self.y_train[0],self.y_train[1]),axis=0)\n",
        "      X_train, y_train= shuffle(X_train, y_train)\n",
        "      eval(\"self.\"+self.opt+\"(X_train, y_train)\")\n",
        "\n",
        "  def predict(self):\n",
        "     approx = np.dot(self.X_test, self.w) - self.b\n",
        "     approx = np.sign(approx)\n",
        "     return np.where(approx<0, 0, approx)\n",
        "\n",
        "  def accuracy(self):\n",
        "    return accuracy_score(self.y_test, self.predict())*100\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5fFCfHW4Xu"
      },
      "source": [
        "## Federated Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57k98FPuWz-t"
      },
      "source": [
        "class Federated_SVM:\n",
        "\n",
        "  def __init__(self, n_clients=5, val=True, val_type='k_fold', k=5, opt='mini_batch_GD', batch_size = 30, learning_rate=0.001, lambda_param=0.01, n_iters=100):\n",
        "    self.n_clients = n_clients\n",
        "    self.learning_rate = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "    self.val = val\n",
        "    self.val_type = val_type\n",
        "    self.client_distribution = []\n",
        "    self.k = k\n",
        "    self.opt = opt\n",
        "    self.batch_size = batch_size\n",
        "    self.X_test = None\n",
        "    self.y_test = None\n",
        "    self.X_clients_test = None\n",
        "    self.y_clients_test = None\n",
        "\n",
        "  def create_clients(self, X_train, y_train, X_clients_test, y_clients_test, X_test, y_test):\n",
        "    self.clients=[]\n",
        "    for i in range(self.n_clients):\n",
        "      self.client_distribution.append(X_train[i][0].shape[0] + X_train[i][1].shape[0])\n",
        "      self.clients.append(SVM(X_train[i],y_train[i], np.concatenate(X_clients_test[i],axis=0), np.concatenate(y_clients_test[i],axis=0), self.val, self.val_type, self.k, self.opt, self.batch_size, self.n_iters, self.learning_rate, self.lambda_param))\n",
        "    self.X_test = copy.deepcopy(X_test)\n",
        "    self.y_test = copy.deepcopy(y_test)\n",
        "  \n",
        "\n",
        "  def average_aggregator(self, parameter_list):\n",
        "    w = np.zeros(parameter_list[0].shape[0])\n",
        "    b = 0\n",
        "    for i in range(0,2*self.n_clients,2):\n",
        "        w = np.add(w,parameter_list[i]*self.client_distribution[i//2]/sum(self.client_distribution))\n",
        "        b = b + parameter_list[i+1]*self.client_distribution[i//2]/sum(self.client_distribution)\n",
        "    return (w, b)\n",
        "\n",
        "  def highest_aggregator(self, parameter_list):\n",
        "    score = 0\n",
        "\n",
        "    for i in range(0,self.n_clients):\n",
        "      acc = self.clients[i].accuracy()\n",
        "      if (acc > score):\n",
        "        w = copy.deepcopy(self.clients[i].w)\n",
        "        b = self.clients[i].b\n",
        "        acc = score\n",
        "\n",
        "    return (w,b)\n",
        "\n",
        "  def random_aggregator(self,parameter_list):\n",
        "    n = random.randint(0,self.n_clients)\n",
        "    w = np.zeros(parameter_list[0].shape[0])\n",
        "    b = 0\n",
        "    for i in range(0,2*self.n_clients,2):\n",
        "      if i//2 != n:\n",
        "        w = np.add(w,parameter_list[i]*self.client_distribution[i//2]/sum(self.client_distribution))\n",
        "        b = b + parameter_list[i+1]*self.client_distribution[i//2]/sum(self.client_distribution)\n",
        "      else:\n",
        "        continue\n",
        "    return (w, b)\n",
        "\n",
        "  def adaptive_scaling_aggregator(self, parameter_list):\n",
        "      clus_param = parameter_list[0]\n",
        "      for i in range(2,len(parameter_list),2):\n",
        "        clus_param = np.row_stack((clus_param,parameter_list[i]))\n",
        "\n",
        "      # print(clus_param)\n",
        "      \n",
        "      fcm = FCM(n_clusters=3)\n",
        "      fcm.fit(clus_param)\n",
        "      res = fcm.predict(clus_param)\n",
        "      prob = fcm.soft_predict(clus_param)\n",
        "      \n",
        "      clus_weights=[]\n",
        "\n",
        "      for i in range(0,3):\n",
        "        sw = np.zeros(len(parameter_list[0]))\n",
        "        sb=0\n",
        "        for j in range(0,len(parameter_list),2):\n",
        "          sw += parameter_list[j]*prob[j//2][i]\n",
        "          sb += parameter_list[j+1]*prob[j//2][i]\n",
        "        \n",
        "\n",
        "        clus_weights.append(sw/np.sum(prob[:][i]))\n",
        "        clus_weights.append(sb/np.sum(prob[:][i]))\n",
        "\n",
        "      for i in range(0,self.n_clients):\n",
        "        \n",
        "        self.clients[i].w = copy.deepcopy(clus_weights[2*res[i]])\n",
        "        self.clients[i].b = copy.deepcopy(clus_weights[2*res[i]+1])\n",
        "\n",
        "      print(prob)\n",
        "      if res[0]==res[3]:\n",
        "        print(\"clus 1 true\")\n",
        "      else:\n",
        "        print(\"clus 1 false\")\n",
        "\n",
        "      if res[1]==res[4]:\n",
        "        print(\"clus 2 true\")\n",
        "      else:\n",
        "        print(\"clus 2 false\")\n",
        "      \n",
        "      return(self.average_aggregator(parameter_list))\n",
        "\n",
        "    \n",
        "      \n",
        "  def fit(self, g_iters, aggregator):\n",
        "    w_best = np.zeros(self.X_test.shape[1])\n",
        "    b_best = 0\n",
        "    for i in range(0,g_iters):\n",
        "      print('global round',i+1)\n",
        "      for j in range(0,self.n_clients):\n",
        "        if i==0 or aggregator == self.adaptive_scaling_aggregator:\n",
        "          self.clients[j].fit()\n",
        "        else:\n",
        "          self.clients[j].w = copy.deepcopy(w_agg)\n",
        "          self.clients[j].b = copy.deepcopy(b_agg)\n",
        "          self.clients[j].fit()\n",
        "        print('client',j+1,self.clients[j].accuracy())          \n",
        "      parameter_list = []\n",
        "      for k in range(0,self.n_clients):\n",
        "        parameter_list.append(self.clients[k].w)\n",
        "        parameter_list.append(self.clients[k].b)\n",
        "        # print(\"client\",k,self.clients[k].w+[self.clients[k].b])\n",
        "      \n",
        "      w_agg, b_agg = aggregator(parameter_list)\n",
        "      # print(\"agg\",self.accuracy(w_agg,b_agg),\"best\",self.accuracy(w_best,b_best))\n",
        "      if self.accuracy(w_agg,b_agg)>self.accuracy(w_best,b_best) or i==0:\n",
        "        w_best=copy.deepcopy(w_agg)\n",
        "        b_best=copy.deepcopy(b_agg)\n",
        "      print('global test acc',self.accuracy(w_best,b_best))\n",
        "\n",
        "\n",
        "  def predict(self,w,b):\n",
        "     approx = np.dot(self.X_test, w) - b\n",
        "     approx = np.sign(approx)\n",
        "     return np.where(approx<0, 0, 1)\n",
        "  \n",
        "  def accuracy(self,w,b):\n",
        "    return accuracy_score(self.y_test, self.predict(w,b))*100\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhHMLWPW_50"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBaGyMvsXDc_"
      },
      "source": [
        "def create_kmeans_clusters(X, Y, n_clusters = 3, random_state = 0):\n",
        "  clusters = KMeans(n_clusters=n_clusters, random_state=random_state).fit_predict(X)\n",
        "  result = []\n",
        "  for i in range(n_clusters):\n",
        "    result.append(X[clusters == i])\n",
        "    result.append(Y[clusters == i])\n",
        "  return tuple(result)  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3eGAEXtXFaM"
      },
      "source": [
        "def get_clients(class1, class2, n_clusters = 3, n_clients = 5):\n",
        "\n",
        "  clients_X = []\n",
        "  clients_y = []\n",
        "\n",
        "  clientsXtest = []\n",
        "  clientsYtest = []\n",
        "\n",
        "  X_test = []\n",
        "  y_test = []\n",
        "\n",
        "  clusters_1 = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(class1)\n",
        "  clusters_2 = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(class2)\n",
        "\n",
        "  for i in range(n_clusters):\n",
        "\n",
        "    X_train0, X_test0, y_train0, y_test0 = train_test_split(class1[clusters_1 == i],np.zeros((class1[clusters_1 == i].shape[0],)),test_size=0.2)\n",
        "    X_train1, X_test1, y_train1, y_test1 = train_test_split(class2[clusters_2 == i],np.ones((class2[clusters_2 == i].shape[0],)),test_size=0.2)\n",
        "\n",
        "    clients_X.append([X_train0, X_train1])\n",
        "    clients_y.append([y_train0, y_train1])\n",
        "\n",
        "    clientsXtest.append([X_test0,X_test1])\n",
        "    clientsYtest.append([y_test0,y_test1])\n",
        "\n",
        "    X_test.extend([X_test0,X_test1])\n",
        "    y_test.extend([y_test0,y_test1])\n",
        "\n",
        "  for i in range(0,2):\n",
        "    X_train0_ex, X_test0_ex, y_train0_ex, y_test0_ex = train_test_split(clients_X[i][0],clients_y[i][0],test_size=0.5)\n",
        "    X_train1_ex, X_test1_ex, y_train1_ex, y_test1_ex = train_test_split(clients_X[i][1],clients_y[i][1],test_size=0.5)\n",
        "\n",
        "    clients_X.append([X_train0_ex, X_train1_ex])\n",
        "    clients_y.append([y_train0_ex, y_train1_ex])\n",
        "\n",
        "    clients_X[i][0],clients_y[i][0] = copy.deepcopy(X_test0_ex), copy.deepcopy(y_test0_ex)\n",
        "    clients_X[i][1],clients_y[i][1] = copy.deepcopy(X_test1_ex), copy.deepcopy(y_test1_ex)\n",
        "\n",
        "    X_train0_exte, X_test0_exte, y_train0_exte, y_test0_exte = train_test_split(clientsXtest[i][0],clientsYtest[i][0],test_size=0.5)\n",
        "    X_train1_exte, X_test1_exte, y_train1_exte, y_test1_exte = train_test_split(clientsXtest[i][1],clientsYtest[i][1],test_size=0.5)    \n",
        "\n",
        "    clientsXtest.append([X_train0_exte, X_train1_exte])\n",
        "    clientsYtest.append([y_train0_exte, y_train1_exte])\n",
        "\n",
        "    clientsXtest[i][0],clientsYtest[i][0] = copy.deepcopy(X_test0_exte), copy.deepcopy(y_test0_exte)\n",
        "    clientsXtest[i][1],clientsYtest[i][1] = copy.deepcopy(X_test1_exte), copy.deepcopy(y_test1_exte)\n",
        "\n",
        "    X_test.extend([X_test0_exte,X_test1_exte])\n",
        "    y_test.extend([y_test0_exte,y_test1_exte])\n",
        "\n",
        "  X_test = np.concatenate(X_test,axis=0)\n",
        "  y_test = np.concatenate(y_test,axis=0)\n",
        "\n",
        "  return clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeEDnNPfXKig"
      },
      "source": [
        "def get_total_from_clients(clients_X,clients_y):\n",
        "  x_train0 = [i[0] for i in clients_X]\n",
        "  x_train0 = np.concatenate(x_train0, axis=0)\n",
        "  x_train1 = [i[1] for i in clients_X]\n",
        "  x_train1 = np.concatenate(x_train1, axis=0)\n",
        "  y_train0 = [i[0] for i in clients_y]\n",
        "  y_train0 = np.concatenate(y_train0, axis=0)\n",
        "  y_train1 = [i[1] for i in clients_y]\n",
        "  y_train1 = np.concatenate(y_train1, axis=0)\n",
        "\n",
        "  return ([x_train0,x_train1],[y_train0,y_train1])    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DvzahFVXRVO"
      },
      "source": [
        "### Paralysis Related Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeRqt0H-XOeH"
      },
      "source": [
        "def Pre_processing(folder_path):\n",
        "  X = np.zeros((1,2500), dtype=int)\n",
        "  Y = np.zeros((1), dtype=int)\n",
        "  faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "  #print(images_path)\n",
        "  for img_type in ['normal/','droopy/']:\n",
        "    images_path = os.listdir(folder_path+img_type)\n",
        "    for img_path in images_path:\n",
        "      #print(folder_path+img_type+img_path)\n",
        "      image = cv2.imread(folder_path+img_type+img_path)\n",
        "      gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "      faces = faceCascade.detectMultiScale(\n",
        "          gray,\n",
        "          scaleFactor=1.3,\n",
        "          minNeighbors=3,\n",
        "          minSize=(40, 40)\n",
        "      )\n",
        "      if (len(faces)!=1):\n",
        "        print(len(faces),img_path)\n",
        "      else:\n",
        "        for (x,y,w,h) in faces:\n",
        "          gray_resize = cv2.resize(gray[y:y+h,x:x+w], (50,50), interpolation=cv2.INTER_AREA)\n",
        "          #print(np.reshape(gray_resize.flatten(),(1,2500)).shape)\n",
        "          X = np.append(X,np.reshape(gray_resize.flatten(),(1,2500)),axis=0)\n",
        "          if (img_type=='normal/'):\n",
        "            #print('normal')\n",
        "            Y = np.append(Y,1)\n",
        "          elif (img_type=='droopy/'):\n",
        "            #print('sdfsdf')\n",
        "            Y = np.append(Y,0)\n",
        "  X = np.delete(X,0,axis=0)\n",
        "  Y = np.delete(Y,0)\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  return(X,Y)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRsKn460Z9tc"
      },
      "source": [
        "# Loading and combining paralysis data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BhuqLt1bR6H",
        "outputId": "bdf07cf0-4197-42e8-be14-5a0ab60c1a3b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9rQrmhuZ8U2",
        "outputId": "b6b492c9-563c-494f-fb53-05d069b8a2ba"
      },
      "source": [
        "X_train,y_train = Pre_processing(\"/content/gdrive/MyDrive/Colab Notebooks/Paralysis dataset/train/\") #/content/gdrive/MyDrive/Colab Notebooks/Paralysis dataset/train\n",
        "X_test,y_test = Pre_processing(\"/content/gdrive/MyDrive/Colab Notebooks/Paralysis dataset/test/\")\n",
        "X_val,y_val = Pre_processing(\"/content/gdrive/MyDrive/Colab Notebooks/Paralysis dataset/validation/\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 andrew!67.jpg\n",
            "2 catherine9.jpg\n",
            "0 dhands!45.jpg\n",
            "0 dhands!67.jpg\n",
            "0 dhands!90.jpg\n",
            "2 dlow10.jpg\n",
            "2 dlow8.jpg\n",
            "0 dpearson!67.jpg\n",
            "0 dpearson!90.jpg\n",
            "2 ian14.jpg\n",
            "0 jim!90.jpg\n",
            "2 kim18a.jpg\n",
            "2 louise5.jpg\n",
            "0 After-10-years-gracilis-muscle-transfer-Dr-Azizzadeh-215x300.png\n",
            "0 After-Profile-view-Selective-Neurolysis-with-Facial-Rejuvenation-and-Laser-Dr-Azizzadeh-Facial-Paralysis-Institute-215x300.jpg\n",
            "2 27_01.jpg\n",
            "0 Before-Profile-view-Selective-Neurolysis-with-Facial-Rejuvenation-and-Laser-Dr-Azizzadeh-Facial-Paralysis-Institute-215x300.jpg\n",
            "2 images - 2019-08-19T154557.325.jpg\n",
            "0 images - 2019-08-19T154616.157.jpg\n",
            "0 images - 2019-08-19T154833.436.jpg\n",
            "0 images - 2019-08-19T162019.878.jpg\n",
            "0 images - 2019-08-19T164939.183.jpg\n",
            "0 images - 2019-08-19T155332.978.jpg\n",
            "0 images - 2019-08-19T155141.003.jpg\n",
            "0 images - 2019-08-19T155053.204.jpg\n",
            "0 images - 2019-08-19T162900.123.jpg\n",
            "0 images - 2019-08-19T165106.918.jpg\n",
            "0 images - 2019-08-19T163339.898.jpg\n",
            "0 download (9).jpg\n",
            "0 d4.PNG\n",
            "0 images - 2019-08-19T154601.125.jpg\n",
            "0 images - 2019-08-19T163950.969.jpg\n",
            "0 images - 2019-08-19T154726.012.jpg\n",
            "0 images - 2019-08-19T155011.348.jpg\n",
            "0 images - 2019-08-19T165018.790.jpg\n",
            "0 f8.PNG\n",
            "0 images - 2019-08-19T155340.619.jpg\n",
            "0 images - 2019-08-19T155546.330.jpg\n",
            "0 images - 2019-08-19T154626.933.jpg\n",
            "0 images - 2019-08-19T162315.205.jpg\n",
            "0 images - 2019-08-19T155509.251.jpg\n",
            "0 images - 2019-08-19T162033.597.jpg\n",
            "0 images - 2019-08-19T164915.246.jpg\n",
            "0 images - 2019-08-19T165026.470.jpg\n",
            "0 images - 2019-08-19T162440.092.jpg\n",
            "0 images - 2019-08-19T163003.227.jpg\n",
            "0 images - 2019-08-19T162024.309.jpg\n",
            "0 b-33-246x300.jpg\n",
            "0 images - 2019-08-19T154955.508.jpg\n",
            "0 images - 2019-08-19T164317.369.jpg\n",
            "0 Bellspalsy.JPG\n",
            "0 images - 2019-08-19T155407.947.jpg\n",
            "0 images - 2019-08-19T164330.601.jpg\n",
            "2 download (4).jpg\n",
            "0 a-25-195x300.jpg\n",
            "0 images - 2019-08-19T163207.930.jpg\n",
            "0 images - 2019-08-19T162926.107.jpg\n",
            "0 images - 2019-08-23T112315.184.jpg\n",
            "0 images - 2019-08-19T163134.338.jpg\n",
            "0 images - 2019-08-19T155043.612.jpg\n",
            "0 images - 2019-08-19T162827.427.jpg\n",
            "0 images - 2019-08-19T162311.821.jpg\n",
            "0 images - 2019-08-19T164933.919.jpg\n",
            "0 images - 2019-08-19T155659.562.jpg\n",
            "0 images - 2019-08-19T162933.868.jpg\n",
            "0 images - 2019-08-19T155034.925.jpg\n",
            "0 images - 2019-08-19T162139.749.jpg\n",
            "0 images - 2019-08-19T155450.515.jpg\n",
            "0 f4.PNG\n",
            "0 images - 2019-08-19T164047.465.jpg\n",
            "0 images - 2019-08-19T155617.363.jpg\n",
            "0 images - 2019-08-19T165009.935.jpg\n",
            "0 d2.PNG\n",
            "0 images - 2019-08-19T154620.637.jpg\n",
            "0 fd17.PNG\n",
            "0 images - 2019-08-19T163404.402.jpg\n",
            "0 a-33-187x300.jpg\n",
            "0 images - 2019-08-19T162435.715.jpg\n",
            "0 images - 2019-08-19T154720.476.jpg\n",
            "0 images - 2019-08-19T163020.027.jpg\n",
            "0 e1.PNG\n",
            "0 images - 2019-08-19T154630.685.jpg\n",
            "0 images - 2019-08-19T154938.580.jpg\n",
            "0 fg8.PNG\n",
            "0 images - 2019-08-19T155404.395.jpg\n",
            "0 f6.PNG\n",
            "0 images - 2019-08-19T163419.378.jpg\n",
            "0 fg13.PNG\n",
            "0 b-24-195x300.jpg\n",
            "0 images - 2019-08-19T163325.691.jpg\n",
            "0 images - 2019-08-19T162848.275.jpg\n",
            "0 images - 2019-08-19T163115.394.jpg\n",
            "0 images - 2019-08-19T165112.021.jpg\n",
            "0 images - 2019-08-19T162016.710.jpg\n",
            "0 images - 2019-08-19T155556.427.jpg\n",
            "0 fg9.PNG\n",
            "0 a7.PNG\n",
            "0 images - 2019-08-19T163354.707.jpg\n",
            "0 images - 2019-08-19T164649.015.jpg\n",
            "0 images - 2019-08-19T155302.499.jpg\n",
            "0 images - 2019-08-19T155107.316.jpg\n",
            "0 b-20-192x300.jpg\n",
            "0 images - 2019-08-19T154931.116.jpg\n",
            "0 images - 2019-08-19T164415.285.jpg\n",
            "0 images - 2019-08-19T162010.309.jpg\n",
            "0 e2.PNG\n",
            "(1094, 2500)\n",
            "(1094,)\n",
            "0 images - 2019-08-23T122847.738.jpg\n",
            "0 images - 2019-08-23T112432.704.jpg\n",
            "0 images - 2019-08-23T122704.628.jpg\n",
            "0 images - 2019-08-23T112509.496.jpg\n",
            "0 images - 2019-08-23T114346.084.jpg\n",
            "0 images - 2019-08-23T125055.536.jpg\n",
            "0 images - 2019-08-23T124905.062.jpg\n",
            "0 images - 2019-08-23T125222.900.jpg\n",
            "0 images - 2019-08-23T112400.040.jpg\n",
            "0 images - 2019-08-23T121857.773.jpg\n",
            "2 images - 2019-08-23T122853.162.jpg\n",
            "0 images - 2019-08-23T122307.803.jpg\n",
            "0 images - 2019-08-23T124850.174.jpg\n",
            "2 images - 2019-08-23T124947.085.jpg\n",
            "0 images - 2019-08-23T114457.963.jpg\n",
            "0 images - 2019-08-23T124630.150.jpg\n",
            "0 images - 2019-08-23T125901.858.jpg\n",
            "0 images - 2019-08-23T112437.487.jpg\n",
            "0 images - 2019-08-23T120233.992.jpg\n",
            "0 images - 2019-08-23T122859.401.jpg\n",
            "0 images - 2019-08-23T120500.711.jpg\n",
            "0 images - 2019-08-23T112607.472.jpg\n",
            "2 images - 2019-08-23T122740.234.jpg\n",
            "0 images - 2019-08-23T124852.437.jpg\n",
            "2 images - 2019-08-23T124605.029.jpg\n",
            "0 images - 2019-08-23T130000.538.jpg\n",
            "0 images - 2019-08-23T112518.391.jpg\n",
            "0 images - 2019-08-23T122711.842.jpg\n",
            "0 images - 2019-08-23T125726.555.jpg\n",
            "0 images - 2019-08-23T122605.826.jpg\n",
            "2 images - 2019-08-23T114442.751.jpg\n",
            "0 images - 2019-08-23T121312.782.jpg\n",
            "0 images - 2019-08-23T122736.554.jpg\n",
            "0 images - 2019-08-23T122838.498.jpg\n",
            "0 images - 2019-08-23T125816.283.jpg\n",
            "0 images - 2019-08-23T122855.858.jpg\n",
            "(364, 2500)\n",
            "(364,)\n",
            "0 paul!45.jpg\n",
            "0 paul!67.jpg\n",
            "0 paul!90.jpg\n",
            "2 ruth1.jpg\n",
            "0 simon!45.jpg\n",
            "0 simon!90.jpg\n",
            "0 179a.jpg\n",
            "0 ss6.PNG\n",
            "0 images (67).jpg\n",
            "0 images (90).jpg\n",
            "0 r2.PNG\n",
            "0 MMD_face.jpg\n",
            "0 images (68).jpg\n",
            "0 images (32).jpg\n",
            "0 images - 2019-08-23T131436.799.jpg\n",
            "0 images (37).jpg\n",
            "0 images (31).jpg\n",
            "0 stroke-face.jpg\n",
            "0 images (21).jpg\n",
            "0 images (26).jpg\n",
            "0 images - 2019-08-23T130844.390.jpg\n",
            "0 images (3).jpg\n",
            "0 images (54).jpg\n",
            "0 images (39).jpg\n",
            "0 images (40).jpg\n",
            "0 images (43).jpg\n",
            "0 images (97).jpg\n",
            "0 v2.PNG\n",
            "0 images (2).jpg\n",
            "0 images (30).jpg\n",
            "0 images - 2019-08-23T131826.342.jpg\n",
            "2 images (63).jpg\n",
            "0 images (13).jpg\n",
            "0 images (35).jpg\n",
            "3 Portrait-Of-Senior-Man-Suffering-From-Stroke-647711962_1416x2122.jpeg\n",
            "0 images (70).jpg\n",
            "0 images (28).jpg\n",
            "0 images (20).jpg\n",
            "0 images (74).jpg\n",
            "0 images - 2019-08-23T131253.336.jpg\n",
            "0 q2.PNG\n",
            "0 images - 2019-08-23T131822.286.jpg\n",
            "2 Neurological-examination-loss-of-forehead-wrinkles-evidence-of-Bells-phenomenon.png\n",
            "0 images (61).jpg\n",
            "0 q1.PNG\n",
            "0 images (88).jpg\n",
            "2 images (33).jpg\n",
            "0 ss8.PNG\n",
            "0 images (4).jpg\n",
            "0 images (98).jpg\n",
            "0 ss1.PNG\n",
            "(349, 2500)\n",
            "(349,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YHElbanbhkr"
      },
      "source": [
        "total_x = (X_train, X_test, X_val)\n",
        "total_y = (y_train,y_test, y_val)\n",
        "data_x = np.vstack(total_x)\n",
        "data_y = np.hstack(total_y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef7qWOiIRYbj",
        "outputId": "bd682896-cec5-4df4-e6e3-322553137cc6"
      },
      "source": [
        "print(data_x.shape)\n",
        "print(data_y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1807, 2500)\n",
            "(1807,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTjmvFTu3-V1"
      },
      "source": [
        "# getting data ready for FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCm7ZyTxRmde"
      },
      "source": [
        "class0 = []\n",
        "class1 = []\n",
        "for i in range(data_x.shape[0]):\n",
        "  if data_y[i]==0:\n",
        "    class0.append(data_x[i][:])\n",
        "  else:\n",
        "    class1.append(data_x[i][:])  \n",
        "class0 = np.stack(class0,axis=0)/255   \n",
        "class0 = np.unique(class0, axis=0)\n",
        "class1 = np.stack(class1,axis=0)/255 \n",
        "class1 = np.unique(class1, axis=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKkdaHJtUDzN",
        "outputId": "d4e426e1-44a2-435a-e3c7-451604b010c1"
      },
      "source": [
        "print(class0.shape)\n",
        "print(class1.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(680, 2500)\n",
            "(978, 2500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkMCpx0SeWr_"
      },
      "source": [
        "clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test = get_clients(class0, class1, n_clusters = 3, n_clients = 5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Gjix0xBLVW"
      },
      "source": [
        "xtrain_gl, ytrain_gl = get_total_from_clients(clients_X,clients_y)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rep1gnZTIab8"
      },
      "source": [
        "f_svm = Federated_SVM(n_clients = 5, val=False, n_iters=150,opt='stochastic_GD')\n",
        "f_svm.create_clients(clients_X,clients_y,clientsXtest,clientsYtest,X_test,y_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9J_jZBTIaeP"
      },
      "source": [
        "# clf = SVM(xtrain_gl, ytrain_gl, X_test, y_test, val=False,n_iters=1000,opt='mini_batch_GD')\n",
        "# clf.fit()\n",
        "# print(clf.accuracy())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L3neq_4IahF",
        "outputId": "d02a68e3-2691-4e8b-cc1b-6e28e3abc48d"
      },
      "source": [
        "f_svm.fit(10,f_svm.adaptive_scaling_aggregator)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global round 1\n",
            "client 1 95.74468085106383\n",
            "client 2 92.53731343283582\n",
            "client 3 99.0909090909091\n",
            "client 4 95.55555555555556\n",
            "client 5 89.23076923076924\n",
            "[[0.08681692 0.78760666 0.12557642]\n",
            " [0.36241485 0.29427319 0.34331196]\n",
            " [0.01565338 0.02632316 0.95802345]\n",
            " [0.0835704  0.79113191 0.12529769]\n",
            " [0.96329563 0.01925742 0.01744695]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 84.82142857142857\n",
            "global round 2\n",
            "client 1 95.74468085106383\n",
            "client 2 98.50746268656717\n",
            "client 3 100.0\n",
            "client 4 95.55555555555556\n",
            "client 5 95.38461538461539\n",
            "[[0.94833147 0.030078   0.02159053]\n",
            " [0.04934124 0.04494063 0.90571814]\n",
            " [0.00292035 0.9952554  0.00182425]\n",
            " [0.94730712 0.03110446 0.02158842]\n",
            " [0.23127894 0.20102051 0.56770055]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.0625\n",
            "global round 3\n",
            "client 1 97.87234042553192\n",
            "client 2 97.01492537313433\n",
            "client 3 100.0\n",
            "client 4 95.55555555555556\n",
            "client 5 93.84615384615384\n",
            "[[0.97691494 0.01040693 0.01267813]\n",
            " [0.00530175 0.98455045 0.0101478 ]\n",
            " [0.43134807 0.25981484 0.30883709]\n",
            " [0.9806976  0.00869782 0.01060458]\n",
            " [0.01103922 0.01812554 0.97083524]]\n",
            "clus 1 true\n",
            "clus 2 false\n",
            "global test acc 89.0625\n",
            "global round 4\n",
            "client 1 95.74468085106383\n",
            "client 2 95.52238805970148\n",
            "client 3 99.0909090909091\n",
            "client 4 95.55555555555556\n",
            "client 5 92.3076923076923\n",
            "[[0.00439062 0.00220706 0.99340232]\n",
            " [0.01274276 0.9754019  0.01185534]\n",
            " [0.97181944 0.00981165 0.0183689 ]\n",
            " [0.00372618 0.00188183 0.994392  ]\n",
            " [0.33851664 0.37174434 0.28973902]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n",
            "global round 5\n",
            "client 1 100.0\n",
            "client 2 94.02985074626866\n",
            "client 3 99.0909090909091\n",
            "client 4 95.55555555555556\n",
            "client 5 93.84615384615384\n",
            "[[6.43073448e-04 9.98795940e-01 5.60986084e-04]\n",
            " [8.66214284e-01 6.45346491e-02 6.92510671e-02]\n",
            " [4.25863686e-04 3.46177222e-04 9.99227959e-01]\n",
            " [6.04356149e-04 9.98870685e-01 5.24958793e-04]\n",
            " [7.51216674e-01 1.19790616e-01 1.28992710e-01]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n",
            "global round 6\n",
            "client 1 95.74468085106383\n",
            "client 2 94.02985074626866\n",
            "client 3 100.0\n",
            "client 4 95.55555555555556\n",
            "client 5 92.3076923076923\n",
            "[[3.82600531e-04 9.99333255e-01 2.84144794e-04]\n",
            " [8.79033286e-01 5.35731421e-02 6.73935715e-02]\n",
            " [1.78460063e-04 1.04386951e-04 9.99717153e-01]\n",
            " [3.98611349e-04 9.99305020e-01 2.96368453e-04]\n",
            " [8.28193291e-01 7.60446270e-02 9.57620822e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n",
            "global round 7\n",
            "client 1 97.87234042553192\n",
            "client 2 94.02985074626866\n",
            "client 3 93.63636363636364\n",
            "client 4 95.55555555555556\n",
            "client 5 93.84615384615384\n",
            "[[3.21225445e-04 9.99462840e-01 2.15934777e-04]\n",
            " [9.02439025e-01 3.85091753e-02 5.90517994e-02]\n",
            " [7.72646193e-05 3.29679928e-05 9.99889767e-01]\n",
            " [3.31742799e-04 9.99445026e-01 2.23231365e-04]\n",
            " [8.79018095e-01 4.71732493e-02 7.38086556e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n",
            "global round 8\n",
            "client 1 95.74468085106383\n",
            "client 2 95.52238805970148\n",
            "client 3 97.27272727272728\n",
            "client 4 93.33333333333333\n",
            "client 5 93.84615384615384\n",
            "[[7.15872541e-04 9.98800748e-01 4.83379794e-04]\n",
            " [9.12554193e-01 3.19479871e-02 5.54978199e-02]\n",
            " [7.90317910e-05 2.78156454e-05 9.99893153e-01]\n",
            " [7.23532647e-04 9.98785644e-01 4.90823207e-04]\n",
            " [8.84369353e-01 3.77481985e-02 7.78824489e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n",
            "global round 9\n",
            "client 1 95.74468085106383\n",
            "client 2 95.52238805970148\n",
            "client 3 97.27272727272728\n",
            "client 4 91.11111111111111\n",
            "client 5 93.84615384615384\n",
            "[[4.66563159e-03 9.92029064e-01 3.30530421e-03]\n",
            " [9.14288873e-01 2.54282417e-02 6.02828848e-02]\n",
            " [1.31285533e-04 3.40112006e-05 9.99834703e-01]\n",
            " [4.59914407e-03 9.92131844e-01 3.26901157e-03]\n",
            " [8.79047380e-01 3.00993067e-02 9.08533135e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n",
            "global round 10\n",
            "client 1 93.61702127659575\n",
            "client 2 88.05970149253731\n",
            "client 3 98.18181818181819\n",
            "client 4 91.11111111111111\n",
            "client 5 89.23076923076924\n",
            "[[9.80482385e-01 1.13232318e-02 8.19438300e-03]\n",
            " [1.90694213e-02 9.14139558e-01 6.67910206e-02]\n",
            " [3.44642921e-05 1.90327291e-04 9.99775208e-01]\n",
            " [9.81763881e-01 1.04829537e-02 7.75316575e-03]\n",
            " [2.28235841e-02 8.78737781e-01 9.84386350e-02]]\n",
            "clus 1 true\n",
            "clus 2 true\n",
            "global test acc 89.95535714285714\n"
          ]
        }
      ]
    }
  ]
}